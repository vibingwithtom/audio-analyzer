<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Phase 1.5 POC: Audio Recorder Testing</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
        }

        h1 {
            color: white;
            text-align: center;
            margin-bottom: 30px;
            font-size: 2em;
        }

        .section {
            background: white;
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 20px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        .section h2 {
            color: #333;
            margin-bottom: 15px;
            border-bottom: 2px solid #667eea;
            padding-bottom: 10px;
        }

        .preset-selector, .control-group {
            margin-bottom: 15px;
        }

        label {
            display: block;
            margin-bottom: 5px;
            color: #555;
            font-weight: 500;
        }

        select, input, button {
            padding: 10px 15px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 1em;
            transition: all 0.3s ease;
        }

        button {
            background: #667eea;
            color: white;
            border: none;
            cursor: pointer;
            font-weight: 600;
            margin-right: 10px;
            margin-bottom: 10px;
        }

        button:hover {
            background: #5568d3;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
        }

        button:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }

        button.danger {
            background: #ef4444;
        }

        button.danger:hover {
            background: #dc2626;
            box-shadow: 0 4px 12px rgba(239, 68, 68, 0.4);
        }

        button.success {
            background: #10b981;
        }

        button.success:hover {
            background: #059669;
            box-shadow: 0 4px 12px rgba(16, 185, 129, 0.4);
        }

        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
            animation: none;
        }

        .status-indicator.recording {
            background: #ef4444;
            animation: pulse 1s infinite;
        }

        .status-indicator.success {
            background: #10b981;
        }

        .status-indicator.warning {
            background: #f59e0b;
        }

        .status-indicator.error {
            background: #ef4444;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .meter {
            margin: 15px 0;
        }

        .meter-label {
            display: flex;
            justify-content: space-between;
            margin-bottom: 5px;
            font-size: 0.9em;
            color: #666;
        }

        .meter-bar {
            width: 100%;
            height: 24px;
            background: #f0f0f0;
            border-radius: 4px;
            overflow: hidden;
            border: 1px solid #ddd;
            position: relative;
        }

        .meter-fill {
            height: 100%;
            background: linear-gradient(90deg, #10b981, #f59e0b, #ef4444);
            width: 0%;
            transition: width 0.1s linear;
            display: flex;
            align-items: center;
            justify-content: flex-end;
            padding-right: 5px;
            color: white;
            font-size: 0.75em;
            font-weight: 600;
        }

        .info-box {
            background: #f0f4ff;
            border-left: 4px solid #667eea;
            padding: 12px;
            margin: 10px 0;
            border-radius: 4px;
            font-size: 0.9em;
            color: #333;
        }

        .error-box {
            background: #fee;
            border-left: 4px solid #ef4444;
            padding: 12px;
            margin: 10px 0;
            border-radius: 4px;
            font-size: 0.9em;
            color: #c00;
        }

        .success-box {
            background: #efe;
            border-left: 4px solid #10b981;
            padding: 12px;
            margin: 10px 0;
            border-radius: 4px;
            font-size: 0.9em;
            color: #060;
        }

        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 15px 0;
        }

        .result-card {
            background: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 4px;
            padding: 12px;
            text-align: center;
        }

        .result-card label {
            font-size: 0.85em;
            color: #999;
            margin-bottom: 5px;
        }

        .result-card .value {
            font-size: 1.5em;
            font-weight: 600;
            color: #333;
            margin: 8px 0;
        }

        .result-card .status {
            font-size: 0.8em;
            padding: 4px 8px;
            border-radius: 3px;
            display: inline-block;
            margin-top: 5px;
        }

        .status.pass {
            background: #d1fae5;
            color: #065f46;
        }

        .status.warning {
            background: #fef3c7;
            color: #92400e;
        }

        .status.fail {
            background: #fee2e2;
            color: #991b1b;
        }

        #recordingTimer {
            font-size: 2em;
            font-weight: 600;
            text-align: center;
            color: #667eea;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
        }

        .browser-info {
            background: #f0f4ff;
            padding: 10px;
            border-radius: 4px;
            margin-bottom: 15px;
            font-size: 0.9em;
            color: #666;
        }

        .download-link {
            display: inline-block;
            margin-top: 10px;
            padding: 10px 15px;
            background: #10b981;
            color: white;
            text-decoration: none;
            border-radius: 4px;
            font-weight: 600;
        }

        .download-link:hover {
            background: #059669;
        }

        .test-matrix {
            width: 100%;
            border-collapse: collapse;
            margin-top: 15px;
        }

        .test-matrix th,
        .test-matrix td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }

        .test-matrix th {
            background: #f5f5f5;
            font-weight: 600;
            color: #333;
        }

        .test-matrix tr:hover {
            background: #f9f9f9;
        }

        .timer {
            font-family: 'Courier New', monospace;
            font-weight: 600;
            font-size: 1.2em;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Phase 1.5: Audio Recorder POC Testing</h1>

        <!-- Browser Info Section -->
        <div class="section">
            <h2>Browser Compatibility Check</h2>
            <div id="browserInfo" class="browser-info"></div>
            <button onclick="checkCapabilities()">Run Compatibility Check</button>
            <div id="capabilityResults"></div>
        </div>

        <!-- Preset Selection -->
        <div class="section">
            <h2>Preset Configuration</h2>
            <div class="preset-selector">
                <label for="presetSelect">Select Preset:</label>
                <select id="presetSelect" onchange="updatePresetInfo()">
                    <option value="auditions-character-recordings">Character Recordings (48kHz, 24-bit, Mono)</option>
                    <option value="three-hour">Three Hour (44.1kHz, 16-bit, Stereo)</option>
                    <option value="bilingual">Bilingual Conversational (44.1kHz, 16-bit, Stereo)</option>
                </select>
            </div>
            <div id="presetInfo"></div>
        </div>

        <!-- Microphone Test Section -->
        <div class="section">
            <h2>Microphone Test</h2>
            <div class="control-group">
                <button onclick="startMicTest()">Start Mic Test</button>
                <button onclick="stopMicTest()" class="danger">Stop Mic Test</button>
            </div>

            <div id="micTestResults" style="display: none;">
                <h3>Microphone Status</h3>
                <div class="results-grid">
                    <div class="result-card">
                        <label>Input Level (Peak)</label>
                        <div class="meter" style="margin: 8px 0;">
                            <div class="meter-bar">
                                <div class="meter-fill" id="peakMeterFill" style="width: 0%;">0dB</div>
                            </div>
                        </div>
                    </div>
                    <div class="result-card">
                        <label>Noise Floor</label>
                        <div class="value" id="noiseFloorValue">-‚àû dB</div>
                        <div class="status" id="noiseFloorStatus"></div>
                    </div>
                    <div class="result-card">
                        <label>Clipping Status</label>
                        <div class="value" id="clippingStatus">Clean</div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Recording Section -->
        <div class="section">
            <h2>Recording Test</h2>
            <div class="control-group">
                <button id="startRecordBtn" onclick="startRecording()" disabled>
                    <span class="status-indicator"></span>Start Recording
                </button>
                <button id="stopRecordBtn" onclick="stopRecording()" class="danger" disabled>Stop Recording</button>
            </div>

            <div id="recordingStatus" style="display: none;">
                <div id="recordingTimer" class="timer">00:00</div>

                <h3>Real-time Audio Metrics</h3>
                <div class="results-grid">
                    <div class="result-card">
                        <label>Peak Level</label>
                        <div class="meter" style="margin: 8px 0;">
                            <div class="meter-bar">
                                <div class="meter-fill" id="recordPeakMeterFill" style="width: 0%;">0dB</div>
                            </div>
                        </div>
                    </div>
                    <div class="result-card">
                        <label>Average Level</label>
                        <div class="meter" style="margin: 8px 0;">
                            <div class="meter-bar">
                                <div class="meter-fill" id="avgMeterFill" style="width: 0%;">-‚àûdB</div>
                            </div>
                        </div>
                    </div>
                    <div class="result-card">
                        <label>Clipping Detected</label>
                        <div class="value" id="clippingCount">0</div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Recording Results -->
        <div class="section">
            <h2>Recording Results</h2>
            <div id="recordingResults" style="display: none;">
                <h3>Validation Results</h3>
                <div class="results-grid">
                    <div class="result-card">
                        <label>Duration</label>
                        <div class="value" id="resultDuration">-</div>
                    </div>
                    <div class="result-card">
                        <label>Sample Rate</label>
                        <div class="value" id="resultSampleRate">-</div>
                    </div>
                    <div class="result-card">
                        <label>Bit Depth</label>
                        <div class="value" id="resultBitDepth">-</div>
                    </div>
                    <div class="result-card">
                        <label>Channels</label>
                        <div class="value" id="resultChannels">-</div>
                    </div>
                </div>

                <h3>File Information</h3>
                <div class="result-card">
                    <label>File Size:</label>
                    <div class="value" id="fileSize">-</div>
                </div>

                <div id="downloadSection" style="text-align: center; margin-top: 20px;"></div>
            </div>
        </div>

        <!-- Performance Section -->
        <div class="section">
            <h2>Performance Metrics</h2>
            <table class="test-matrix">
                <thead>
                    <tr>
                        <th>Metric</th>
                        <th>Value</th>
                        <th>Status</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Initialization Time</td>
                        <td id="initTime">-</td>
                        <td><span id="initTimeStatus" class="status pass">‚úì</span></td>
                    </tr>
                    <tr>
                        <td>Peak Detection Latency</td>
                        <td id="peakLatency">-</td>
                        <td><span id="peakLatencyStatus" class="status pass">‚úì</span></td>
                    </tr>
                    <tr>
                        <td>CPU Usage (est.)</td>
                        <td id="cpuUsage">-</td>
                        <td><span id="cpuStatus" class="status pass">‚úì</span></td>
                    </tr>
                    <tr>
                        <td>Memory Usage</td>
                        <td id="memUsage">-</td>
                        <td><span id="memStatus" class="status pass">‚úì</span></td>
                    </tr>
                </tbody>
            </table>
        </div>

        <!-- Test Log -->
        <div class="section">
            <h2>Test Log</h2>
            <button onclick="clearLog()">Clear Log</button>
            <div id="testLog" style="background: #f5f5f5; padding: 15px; margin-top: 15px; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 0.85em; color: #333; max-height: 300px; overflow-y: auto;"></div>
        </div>
    </div>

    <script>
        // ============================================
        // Custom 24-bit PCM WAV Encoder
        // ============================================

        class WAV24Encoder {
            constructor(sampleRate, channels, bitDepth) {
                this.sampleRate = sampleRate;
                this.channels = channels;
                this.bitDepth = bitDepth;
                this.samples = [];
                this.bytesPerSample = bitDepth / 8;
            }

            // Convert Float32 sample to signed integer (16-bit or 24-bit)
            float32ToInt(float32, bitDepth) {
                // Clamp to [-1, 1]
                let sample = Math.max(-1, Math.min(1, float32));

                if (bitDepth === 24) {
                    // Convert to 24-bit signed integer
                    sample = sample < 0 ? sample * 0x800000 : sample * 0x7FFFFF;
                } else if (bitDepth === 16) {
                    // Convert to 16-bit signed integer
                    sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                }

                return Math.floor(sample);
            }

            // Add Float32 samples (from Web Audio API)
            addSamples(float32Array) {
                for (let i = 0; i < float32Array.length; i++) {
                    const intSample = this.float32ToInt(float32Array[i], this.bitDepth);
                    this.samples.push(intSample);
                }
            }

            // Convert integer samples to bytes (little-endian)
            samplesToBytes() {
                const byteArray = new Uint8Array(this.samples.length * this.bytesPerSample);

                if (this.bitDepth === 24) {
                    // 24-bit: 3 bytes per sample
                    for (let i = 0; i < this.samples.length; i++) {
                        const sample = this.samples[i];
                        byteArray[i * 3] = sample & 0xFF;                    // LSB
                        byteArray[i * 3 + 1] = (sample >> 8) & 0xFF;        // Middle
                        byteArray[i * 3 + 2] = (sample >> 16) & 0xFF;       // MSB
                    }
                } else if (this.bitDepth === 16) {
                    // 16-bit: 2 bytes per sample
                    for (let i = 0; i < this.samples.length; i++) {
                        const sample = this.samples[i];
                        byteArray[i * 2] = sample & 0xFF;                   // LSB
                        byteArray[i * 2 + 1] = (sample >> 8) & 0xFF;        // MSB
                    }
                }

                return byteArray;
            }

            // Build WAV file with RIFF header
            getWAVBlob() {
                const pcmData = this.samplesToBytes();
                const dataSize = pcmData.length;
                const headerSize = 44; // WAV header is 44 bytes
                const fileSize = headerSize + dataSize - 8;

                // Create WAV header
                const header = new ArrayBuffer(headerSize);
                const view = new DataView(header);
                const offset = 0;

                // RIFF header
                const writeString = (offset, str) => {
                    for (let i = 0; i < str.length; i++) {
                        view.setUint8(offset + i, str.charCodeAt(i));
                    }
                };

                writeString(0, 'RIFF');
                view.setUint32(4, fileSize, true);  // File size - 8
                writeString(8, 'WAVE');

                // fmt sub-chunk
                writeString(12, 'fmt ');
                view.setUint32(16, 16, true);       // Subchunk1Size (16 for PCM)
                view.setUint16(20, 1, true);        // AudioFormat (1 = PCM)
                view.setUint16(22, this.channels, true);  // NumChannels
                view.setUint32(24, this.sampleRate, true); // SampleRate

                // ByteRate
                const byteRate = this.sampleRate * this.channels * this.bytesPerSample;
                view.setUint32(28, byteRate, true);

                // BlockAlign
                view.setUint16(32, this.channels * this.bytesPerSample, true);

                // BitsPerSample
                view.setUint16(34, this.bitDepth, true);

                // data sub-chunk
                writeString(36, 'data');
                view.setUint32(40, dataSize, true); // Subchunk2Size

                // Combine header and PCM data
                const wavData = new Uint8Array(headerSize + dataSize);
                wavData.set(new Uint8Array(header), 0);
                wavData.set(pcmData, headerSize);

                return new Blob([wavData], { type: 'audio/wav' });
            }

            getSampleCount() {
                return this.samples.length;
            }
        }

        // ============================================
        // Configuration & State Management
        // ============================================

        const PRESETS = {
            'auditions-character-recordings': {
                name: 'Character Recordings',
                sampleRate: 48000,
                bitDepth: 24,
                channels: 1,
                minDuration: 30
            },
            'three-hour': {
                name: 'Three Hour',
                sampleRate: 44100,
                bitDepth: 16,
                channels: 2,
                minDuration: 60
            },
            'bilingual': {
                name: 'Bilingual Conversational',
                sampleRate: 44100,
                bitDepth: 16,
                channels: 2,
                minDuration: 60
            }
        };

        let state = {
            currentPreset: 'auditions-character-recordings',
            isRecording: false,
            isMicTesting: false,
            recordingStartTime: null,
            recordingBlob: null,
            audioContext: null,
            analyser: null,
            stream: null,
            wavEncoder: null,
            processorNode: null,
            sourceNode: null,
            peakLevel: -Infinity,
            avgLevel: -Infinity,
            clippingCount: 0,
            recordingMetrics: {
                peakLevels: [],
                avgLevels: [],
                clippingFrames: 0
            }
        };

        // ============================================
        // Utility Functions
        // ============================================

        function log(message) {
            const timestamp = new Date().toLocaleTimeString();
            const logElement = document.getElementById('testLog');
            logElement.innerHTML += `[${timestamp}] ${message}\n`;
            logElement.scrollTop = logElement.scrollHeight;
            console.log(`[${timestamp}] ${message}`);
        }

        function clearLog() {
            document.getElementById('testLog').innerHTML = '';
        }

        function formatFrequency(hz) {
            return (hz / 1000).toFixed(1) + ' kHz';
        }

        function updatePresetInfo() {
            const preset = PRESETS[state.currentPreset];
            const html = `
                <div class="info-box">
                    <strong>Sample Rate:</strong> ${formatFrequency(preset.sampleRate)}<br>
                    <strong>Bit Depth:</strong> ${preset.bitDepth}-bit<br>
                    <strong>Channels:</strong> ${preset.channels === 1 ? 'Mono' : 'Stereo'}<br>
                    <strong>Min Duration:</strong> ${preset.minDuration}s
                </div>
            `;
            document.getElementById('presetInfo').innerHTML = html;
        }

        // ============================================
        // Browser Compatibility Check
        // ============================================

        function checkCapabilities() {
            log('Checking browser capabilities...');
            const capabilities = [];
            const issues = [];

            // Check for getUserMedia
            if (navigator.mediaDevices?.getUserMedia) {
                capabilities.push('‚úì getUserMedia API');
            } else {
                issues.push('‚úó getUserMedia API not supported');
            }

            // Check for AudioContext
            const AudioContext = window.AudioContext || window.webkitAudioContext;
            if (AudioContext) {
                capabilities.push('‚úì Web Audio API');
            } else {
                issues.push('‚úó Web Audio API not supported');
            }

            // Check for MediaRecorder
            if (window.MediaRecorder) {
                capabilities.push('‚úì MediaRecorder API');
            } else {
                issues.push('‚úó MediaRecorder API not supported');
            }

            // Check for AudioWorklet (preferred for recording)
            if (window.AudioWorklet || window.AudioContext?.prototype?.createScriptProcessor) {
                capabilities.push('‚úì AudioWorklet/ScriptProcessor (for sample capture)');
            } else {
                issues.push('‚ö† AudioWorklet not available (will use ScriptProcessor)');
            }

            // Check for HTTPS
            if (location.protocol === 'https:' || location.hostname === 'localhost') {
                capabilities.push('‚úì HTTPS (or localhost)');
            } else {
                issues.push('‚úó HTTPS required for microphone access');
            }

            // Display browser info
            const browserInfo = `
                <strong>Browser:</strong> ${navigator.userAgent.split('/')[navigator.userAgent.split('/').length - 1].split(' ')[0]}<br>
                <strong>Platform:</strong> ${navigator.platform}<br>
                <strong>Language:</strong> ${navigator.language}
            `;
            document.getElementById('browserInfo').innerHTML = browserInfo;

            // Display results
            const resultsHtml = `
                <h3>Capabilities</h3>
                <div class="${issues.length === 0 ? 'success-box' : 'error-box'}">
                    ${capabilities.map(c => `<div>${c}</div>`).join('')}
                    ${issues.length > 0 ? `<hr style="margin: 10px 0;"><strong>Issues:</strong>${issues.map(i => `<div>${i}</div>`).join('')}` : ''}
                </div>
            `;
            document.getElementById('capabilityResults').innerHTML = resultsHtml;
            log(`Capabilities checked: ${capabilities.length} supported, ${issues.length} issues`);
        }

        // ============================================
        // Microphone Test
        // ============================================

        async function startMicTest() {
            try {
                log('Starting microphone test...');
                const initStart = performance.now();

                const preset = PRESETS[state.currentPreset];

                // Request microphone access
                state.stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    }
                });

                log('Microphone access granted');

                // Create audio context
                const AudioContext = window.AudioContext || window.webkitAudioContext;
                state.audioContext = new AudioContext({
                    sampleRate: preset.sampleRate
                });

                // Create analyser
                state.analyser = state.audioContext.createAnalyser();
                state.analyser.fftSize = 2048;

                const source = state.audioContext.createMediaStreamSource(state.stream);
                source.connect(state.analyser);

                const initEnd = performance.now();
                document.getElementById('initTime').textContent = `${(initEnd - initStart).toFixed(0)}ms`;

                state.isMicTesting = true;
                document.getElementById('micTestResults').style.display = 'block';

                log('Audio context created, analyzing microphone input...');
                analyzeAudio();

            } catch (error) {
                log(`Error: ${error.message}`);
                alert(`Microphone Error: ${error.message}`);
            }
        }

        function analyzeAudio() {
            if (!state.isMicTesting) return;

            const dataArray = new Float32Array(state.analyser.frequencyBinCount);
            state.analyser.getFloatTimeDomainData(dataArray);

            // Calculate peak level
            let peak = 0;
            let sum = 0;
            for (let i = 0; i < dataArray.length; i++) {
                const abs = Math.abs(dataArray[i]);
                peak = Math.max(peak, abs);
                sum += abs;
            }

            const peakDb = peak > 0 ? (20 * Math.log10(peak)).toFixed(1) : '-‚àû';
            const avgDb = (sum / dataArray.length) > 0 ? (20 * Math.log10(sum / dataArray.length)).toFixed(1) : '-‚àû';

            // Update peak meter
            const peakPercent = Math.min(100, (parseFloat(peakDb) + 60) * 1.67);
            document.getElementById('peakMeterFill').style.width = `${Math.max(0, peakPercent)}%`;
            document.getElementById('peakMeterFill').textContent = `${peakDb}dB`;

            // Update noise floor estimate (average of low values)
            const sortedSamples = Array.from(dataArray).filter(v => Math.abs(v) > 0.001).sort();
            const noiseFloor = sortedSamples.length > 100 ? 20 * Math.log10(sortedSamples[Math.floor(sortedSamples.length * 0.1)]) : -Infinity;

            if (noiseFloor > -Infinity) {
                document.getElementById('noiseFloorValue').textContent = `${noiseFloor.toFixed(1)} dB`;

                let status = 'pass';
                let statusText = '‚úì Good';
                if (noiseFloor > -50) {
                    status = 'fail';
                    statusText = '‚úó High Noise';
                } else if (noiseFloor > -60) {
                    status = 'warning';
                    statusText = '‚ö† Fair';
                }

                const statusEl = document.getElementById('noiseFloorStatus');
                statusEl.className = `status ${status}`;
                statusEl.textContent = statusText;
            }

            // Clipping detection
            const clippingThreshold = 0.99;
            const clippingSamples = dataArray.filter(v => Math.abs(v) >= clippingThreshold).length;
            const clippingPercent = (clippingSamples / dataArray.length) * 100;

            if (clippingPercent > 1) {
                document.getElementById('clippingStatus').textContent = '‚ö† Clipping!';
            }

            requestAnimationFrame(analyzeAudio);
        }

        function stopMicTest() {
            log('Stopping microphone test...');
            state.isMicTesting = false;

            if (state.stream) {
                state.stream.getTracks().forEach(track => track.stop());
            }

            if (state.audioContext) {
                state.audioContext.close();
            }

            state.stream = null;
            state.audioContext = null;
            state.analyser = null;

            document.getElementById('micTestResults').style.display = 'none';
            document.getElementById('startRecordBtn').disabled = false;

            log('Microphone test stopped');
        }

        // ============================================
        // Recording Functions (Using Custom 24-bit WAV Encoder)
        // ============================================

        async function startRecording() {
            try {
                log('Initializing recording with custom WAV encoder...');
                const initStart = performance.now();

                const preset = PRESETS[state.currentPreset];

                // Request microphone access with preset constraints
                state.stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: { exact: preset.sampleRate },
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    }
                });

                log(`Microphone stream acquired at ${preset.sampleRate}Hz`);

                // Create audio context for analysis and capture
                const AudioContext = window.AudioContext || window.webkitAudioContext;
                state.audioContext = new AudioContext({
                    sampleRate: preset.sampleRate
                });

                // Create analyser for real-time metrics
                state.analyser = state.audioContext.createAnalyser();
                state.analyser.fftSize = 2048;

                // Create media stream source
                state.sourceNode = state.audioContext.createMediaStreamSource(state.stream);

                // Create WAV encoder
                state.wavEncoder = new WAV24Encoder(
                    preset.sampleRate,
                    preset.channels,
                    preset.bitDepth
                );
                log(`WAV24Encoder created: ${preset.sampleRate}Hz, ${preset.channels} channels, ${preset.bitDepth}-bit`);

                // Create ScriptProcessorNode to capture samples
                const bufferSize = 4096;
                state.processorNode = state.audioContext.createScriptProcessor(bufferSize, 1, 1);

                // Audio routing:
                // sourceNode -> analyser (for real-time metrics)
                //           -> processor (for sample capture)
                //           -> destination (to speakers)
                state.sourceNode.connect(state.analyser);
                state.sourceNode.connect(state.processorNode);
                state.processorNode.connect(state.audioContext.destination);

                // Handle audio samples
                state.processorNode.onaudioprocess = (event) => {
                    if (!state.isRecording) return;

                    // Get input samples
                    const inputData = event.inputBuffer.getChannelData(0);

                    // Add samples to encoder
                    state.wavEncoder.addSamples(inputData);
                };

                const initEnd = performance.now();
                document.getElementById('initTime').textContent = `${(initEnd - initStart).toFixed(0)}ms`;

                state.isRecording = true;
                state.recordingStartTime = Date.now();
                state.recordingMetrics = { peakLevels: [], avgLevels: [], clippingFrames: 0 };
                state.clippingCount = 0;

                document.getElementById('recordingStatus').style.display = 'block';
                document.getElementById('startRecordBtn').disabled = true;
                document.getElementById('stopRecordBtn').disabled = false;
                document.getElementById('recordingResults').style.display = 'none';

                log(`Recording started with custom encoder: ${preset.name}`);
                updateRecordingTimer();
                recordingAnalysis();

            } catch (error) {
                log(`Recording error: ${error.message}`);
                alert(`Recording Error: ${error.message}`);
            }
        }

        function updateRecordingTimer() {
            if (!state.isRecording) return;

            const elapsed = Math.floor((Date.now() - state.recordingStartTime) / 1000);
            const minutes = Math.floor(elapsed / 60);
            const seconds = elapsed % 60;

            document.getElementById('recordingTimer').textContent =
                `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;

            setTimeout(updateRecordingTimer, 100);
        }

        function recordingAnalysis() {
            if (!state.isRecording || !state.analyser) return;

            const dataArray = new Float32Array(state.analyser.frequencyBinCount);
            state.analyser.getFloatTimeDomainData(dataArray);

            // Calculate metrics
            let peak = 0;
            let sum = 0;
            let clipping = 0;

            for (let i = 0; i < dataArray.length; i++) {
                const abs = Math.abs(dataArray[i]);
                peak = Math.max(peak, abs);
                sum += abs;
                if (abs >= 0.99) clipping++;
            }

            const peakDb = peak > 0 ? (20 * Math.log10(peak)).toFixed(1) : '-‚àû';
            const avgDb = (sum / dataArray.length) > 0 ? (20 * Math.log10(sum / dataArray.length)).toFixed(1) : '-‚àû';

            state.recordingMetrics.peakLevels.push(parseFloat(peakDb));
            state.recordingMetrics.avgLevels.push(parseFloat(avgDb));
            if (clipping > dataArray.length * 0.01) {
                state.recordingMetrics.clippingFrames++;
                state.clippingCount++;
            }

            // Update peak meter
            const peakPercent = Math.min(100, (parseFloat(peakDb) + 60) * 1.67);
            document.getElementById('recordPeakMeterFill').style.width = `${Math.max(0, peakPercent)}%`;
            document.getElementById('recordPeakMeterFill').textContent = `${peakDb}dB`;

            // Update avg meter
            const avgPercent = Math.min(100, (parseFloat(avgDb) + 60) * 1.67);
            document.getElementById('avgMeterFill').style.width = `${Math.max(0, avgPercent)}%`;
            document.getElementById('avgMeterFill').textContent = `${avgDb}dB`;

            // Update clipping count
            document.getElementById('clippingCount').textContent = state.clippingCount;

            requestAnimationFrame(recordingAnalysis);
        }

        async function stopRecording() {
            log('Stopping recording...');
            state.isRecording = false;

            // Disconnect audio nodes
            if (state.processorNode) {
                state.processorNode.disconnect();
                state.processorNode.onaudioprocess = null;
            }

            if (state.analyser) {
                state.analyser.disconnect();
            }

            if (state.sourceNode) {
                state.sourceNode.disconnect();
            }

            if (state.stream) {
                state.stream.getTracks().forEach(track => track.stop());
            }

            // Get WAV blob from encoder
            if (state.wavEncoder) {
                state.recordingBlob = state.wavEncoder.getWAVBlob();
                const sampleCount = state.wavEncoder.getSampleCount();
                log(`WAV blob created: ${state.recordingBlob.type}, size: ${(state.recordingBlob.size / 1024 / 1024).toFixed(2)} MB`);
                log(`Total samples captured: ${sampleCount}`);
                analyzeRecording();
            }

            if (state.audioContext) {
                state.audioContext.close();
            }

            document.getElementById('recordingStatus').style.display = 'none';
            document.getElementById('startRecordBtn').disabled = false;
            document.getElementById('stopRecordBtn').disabled = true;

            log('Recording stopped');
        }

        // Parse WAV header to extract metadata
        function parseWAVHeader(arrayBuffer) {
            const view = new DataView(arrayBuffer);

            // Check for RIFF header
            if (view.getUint32(0, false) !== 0x46464952) { // "RIFF"
                throw new Error('Not a valid WAV file - missing RIFF header');
            }

            // Find fmt chunk
            let pos = 12; // Start after "RIFF....WAVE"
            let sampleRate = 0, channels = 0, bitDepth = 0, duration = 0, audioFormat = 0;

            while (pos < arrayBuffer.byteLength) {
                const chunkID = view.getUint32(pos, false);
                const chunkSize = view.getUint32(pos + 4, true);

                if (chunkID === 0x20746d66) { // "fmt " chunk
                    // Audio format (should be 1 for PCM)
                    audioFormat = view.getUint16(pos + 8, true);
                    channels = view.getUint16(pos + 10, true);
                    sampleRate = view.getUint32(pos + 12, true);
                    bitDepth = view.getUint16(pos + 22, true);
                }

                if (chunkID === 0x61746164) { // "data" chunk
                    const dataSize = chunkSize;
                    duration = dataSize / (sampleRate * channels * (bitDepth / 8));
                }

                pos += 8 + chunkSize;
            }

            return { audioFormat, sampleRate, channels, bitDepth, duration };
        }

        async function analyzeRecording() {
            try {
                log('Analyzing recorded PCM WAV...');
                const preset = PRESETS[state.currentPreset];
                const blob = state.recordingBlob;

                log(`Recorded blob type: ${blob.type}, size: ${(blob.size / 1024 / 1024).toFixed(2)} MB`);

                // Parse WAV header
                const arrayBuffer = await blob.arrayBuffer();

                let metadata;
                try {
                    metadata = parseWAVHeader(arrayBuffer);
                    log(`üîç WAV Header Analysis:`);
                    log(`   - Audio Format: ${metadata.audioFormat === 1 ? 'PCM' : 'Compressed/Unknown'}`);
                    log(`   - Sample Rate (actual): ${metadata.sampleRate}Hz`);
                    log(`   - Channels (actual): ${metadata.channels}`);
                    log(`   - Bit Depth (actual): ${metadata.bitDepth}-bit`);

                    // CRITICAL: Check if RecordRTC ignored our bit depth request
                    if (metadata.bitDepth !== preset.bitDepth) {
                        log(`‚ö†Ô∏è CRITICAL: Preset requested ${preset.bitDepth}-bit but file is ${metadata.bitDepth}-bit!`);
                        log(`   RecordRTC may not support requested bit depth.`);
                    }
                } catch (parseError) {
                    log(`Warning: Could not parse WAV header: ${parseError.message}`);
                    metadata = {
                        sampleRate: preset.sampleRate,
                        channels: preset.channels,
                        bitDepth: preset.bitDepth,
                        duration: 0
                    };
                }

                // Also try WebAudio decode for validation
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                let audioBuffer;
                try {
                    audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                    metadata.duration = audioBuffer.duration;
                    log(`WebAudio decode successful: ${audioBuffer.duration.toFixed(2)}s`);
                } catch (decodeError) {
                    log(`WebAudio decode warning: ${decodeError.message} (WAV header parsing will be used)`);
                }

                // Use parsed metadata (from WAV header)
                const duration = metadata.duration || 0;
                const sampleRate = metadata.sampleRate;
                const channels = metadata.channels;
                const bitDepth = metadata.bitDepth;

                // Update results with WAV header values
                document.getElementById('resultDuration').textContent = `${duration.toFixed(2)}s`;
                document.getElementById('resultSampleRate').textContent = formatFrequency(sampleRate);
                document.getElementById('resultBitDepth').textContent = `${bitDepth}-bit`;
                document.getElementById('resultChannels').textContent = channels === 1 ? 'Mono' : 'Stereo';
                document.getElementById('fileSize').textContent = `${(blob.size / 1024 / 1024).toFixed(2)} MB`;

                // Validate against preset
                const sampleRateMatch = sampleRate === preset.sampleRate;
                const bitDepthMatch = bitDepth === preset.bitDepth;
                const channelsMatch = channels === preset.channels;
                const durationOk = duration >= preset.minDuration;
                const isPCM = metadata.audioFormat === 1; // Verify it's actually PCM

                let validationHtml = `
                    <div class="results-grid" style="margin-top: 15px;">
                        <div class="result-card">
                            <label>Format</label>
                            <div class="status ${isPCM ? 'pass' : 'fail'}">
                                ${isPCM ? '‚úì Uncompressed PCM' : '‚úó Compressed'}
                            </div>
                        </div>
                        <div class="result-card">
                            <label>Sample Rate</label>
                            <div class="status ${sampleRateMatch ? 'pass' : 'fail'}">
                                ${sampleRateMatch ? `‚úì ${sampleRate}Hz` : `‚úó ${sampleRate}Hz (wanted ${preset.sampleRate}Hz)`}
                            </div>
                        </div>
                        <div class="result-card">
                            <label>Bit Depth</label>
                            <div class="status ${bitDepthMatch ? 'pass' : 'fail'}">
                                ${bitDepthMatch ? `‚úì ${bitDepth}-bit` : `‚ö†Ô∏è ${bitDepth}-bit (wanted ${preset.bitDepth}-bit)`}
                            </div>
                        </div>
                        <div class="result-card">
                            <label>Channels</label>
                            <div class="status ${channelsMatch ? 'pass' : 'fail'}">
                                ${channelsMatch ? `‚úì ${channels === 1 ? 'Mono' : 'Stereo'}` : `‚úó ${channels} (wanted ${preset.channels})`}
                            </div>
                        </div>
                        <div class="result-card">
                            <label>Duration</label>
                            <div class="status ${durationOk ? 'pass' : 'fail'}">
                                ${durationOk ? `‚úì ${duration.toFixed(2)}s` : `‚úó ${duration.toFixed(2)}s (min ${preset.minDuration}s)`}
                            </div>
                        </div>
                    </div>
                `;

                // Add warning if bit depth doesn't match
                if (!bitDepthMatch) {
                    validationHtml += `
                        <div class="info-box" style="border-left-color: #f59e0b; background: #fffbeb;">
                            <strong>‚ö†Ô∏è Bit Depth Note:</strong> RecordRTC recorded at ${bitDepth}-bit instead of requested ${preset.bitDepth}-bit.
                            This may be a library limitation. Check Phase 1.5 findings for details.
                        </div>
                    `;
                }

                // Add download link
                const url = URL.createObjectURL(blob);
                const link = document.createElement('a');
                link.href = url;

                // Determine file extension based on MIME type
                let extension = 'wav';
                if (blob.type.includes('webm')) extension = 'webm';
                else if (blob.type.includes('ogg')) extension = 'ogg';
                else if (blob.type.includes('mp4')) extension = 'mp4';

                link.download = `recording-${Date.now()}.${extension}`;

                validationHtml += `
                    <div style="text-align: center; margin-top: 20px;">
                        <a href="${url}" download class="download-link">üì• Download Recording (${blob.type || 'audio/' + extension})</a>
                    </div>
                `;

                document.getElementById('downloadSection').innerHTML = validationHtml;
                document.getElementById('recordingResults').style.display = 'block';

                // Log stats
                const avgPeak = (state.recordingMetrics.peakLevels.reduce((a, b) => a + b, 0) / state.recordingMetrics.peakLevels.length).toFixed(1);
                log(`Recording analysis complete: ${duration.toFixed(2)}s @ ${formatFrequency(sampleRate)}, ${channels} channels`);
                log(`Peak levels - Average: ${avgPeak}dB, Max: ${Math.max(...state.recordingMetrics.peakLevels).toFixed(1)}dB`);
                log(`Clipping frames detected: ${state.recordingMetrics.clippingFrames}`);

            } catch (error) {
                log(`Analysis error: ${error.message}`);
                alert(`Error analyzing recording: ${error.message}`);
            }
        }

        // ============================================
        // Initialization
        // ============================================

        window.addEventListener('load', () => {
            log('Page loaded, ready to test');
            updatePresetInfo();
            checkCapabilities();

            // Update preset when selector changes
            document.getElementById('presetSelect').addEventListener('change', (e) => {
                state.currentPreset = e.target.value;
                updatePresetInfo();
                log(`Preset changed to: ${PRESETS[state.currentPreset].name}`);
            });
        });

        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            if (state.stream) {
                state.stream.getTracks().forEach(track => track.stop());
            }
            if (state.audioContext) {
                state.audioContext.close();
            }
        });
    </script>
</body>
</html>
